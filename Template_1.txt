//Template1  = VIDEO edit with audio + 10 20 30 40 seconds moving..

import React, { useRef, useState, useEffect } from 'react';
import videoSource from "../data/tamp1.mp4";
import axios from 'axios';

const VideoWatermark = () => {
  const videoRef = useRef(null);
  const [showWatermark, setShowWatermark] = useState(false);
  const [watermarkImage, setWatermarkImage] = useState(null);
  //const [userText, setUserText] = useState("");
  const [binaryVideoData, setBinaryVideoData] = useState(null);

  const handleImageChange = (e) => {
    const file = e.target.files[0];
    if (file) {
      const reader = new FileReader();
      reader.onloadend = () => {
        setWatermarkImage(reader.result);
      };
      reader.readAsDataURL(file);
    }
  };

  // const handleTextChange = (e) => {
  //   setUserText(e.target.value);
  // };

  const addWatermark = () => {
    setShowWatermark(true);
  };

  const downloadWithWatermark = async () => {
    const video = videoRef.current;
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    
    const audioCtx = new AudioContext();
    const dest = audioCtx.createMediaStreamDestination();

    const videoStream = canvas.captureStream();
    const audioStream = dest.stream;

    const recorder = new MediaRecorder(new MediaStream([videoStream.getVideoTracks()[0], audioStream.getAudioTracks()[0]]), { mimeType: 'video/webm;codecs=vp9,opus' });
    const chunks = [];

    recorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        chunks.push(event.data);
      }
    };

    recorder.onstop = () => {
      const blob = new Blob(chunks, { type: 'video/webm' });
      const downloadLink = document.createElement('a');
      downloadLink.href = URL.createObjectURL(blob);
      downloadLink.download = 'video_with_watermark.mkv';
      downloadLink.click();
      window.alert('Video Successfully Fetched');
    };

    recorder.start();
    video.play();

    const drawFrame = () => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (showWatermark && watermarkImage) {
        const watermark = new Image();
        watermark.src = watermarkImage;

        const watermarkWidth = 150;
        const watermarkHeight = watermarkWidth;

        // Calculate the position based on the elapsed time
        const elapsedTime = video.currentTime;
        let watermarkPosition;

        if (elapsedTime <= 10) {
          watermarkPosition = { x: 10, y: canvas.height - 10 - watermarkHeight };
        } else if (elapsedTime <= 20) {
          watermarkPosition = { x: canvas.width - 10 - watermarkWidth, y: canvas.height - 10 - watermarkHeight };
        } else if (elapsedTime <= 30) {
          watermarkPosition = { x: canvas.width - 10 - watermarkWidth, y: 10 };
        } else if (elapsedTime <= 40) {
          // Display at the center of the video
          watermarkPosition = { x: 10, y: 10 };
        } else {
          watermarkPosition = {
            x: (canvas.width - watermarkWidth) / 2,
            y: (canvas.height - watermarkHeight) / 2,
          };
        }

        ctx.save();
        ctx.beginPath();
        ctx.arc(watermarkPosition.x + watermarkWidth / 2, watermarkPosition.y + watermarkHeight / 2, watermarkWidth / 2, 0, 2 * Math.PI);
        ctx.closePath();
        ctx.clip();

        ctx.drawImage(watermark, watermarkPosition.x, watermarkPosition.y, watermarkWidth, watermarkHeight);
        ctx.restore();
      }

      if (!video.ended) {
        requestAnimationFrame(drawFrame);
      }
    };

    drawFrame();

    // Connect the audio context to the destination
    audioCtx.resume().then(() => {
      const audioSource = audioCtx.createMediaElementSource(video);
      audioSource.connect(dest);
    });

    setTimeout(() => {
      recorder.stop();
      video.pause();
    }, video.duration * 1000);
  };

  // Fetch the binary video data from the server
  useEffect(() => {
    axios.get("/api/auth/pullVideo", { responseType: 'arraybuffer' })
      .then(res => {
        // Create a Blob from the binary data
        const blob = new Blob([res.data], { type: 'video/mp4' });
        setBinaryVideoData(blob);
      })
      .catch(err => console.log(err));
  }, []);

  // Update the video source when binary data changes
  useEffect(() => {
    if (binaryVideoData) {
      // Create a URL for the Blob
      const videoURL = URL.createObjectURL(binaryVideoData);

      // Set the video source to the created URL
      const videoPlayer = videoRef.current;
      if (videoPlayer) {
        videoPlayer.src = videoURL;
      }
    }
  }, [binaryVideoData]);


  return (
    <div style={{ position: 'relative' }}>
      <video ref={videoRef} controls width="500">
        <source src={binaryVideoData ? videoRef.current.src : ''} type="video/mp4" />
        Your browser does not support the video tag.
      </video>
      {showWatermark && watermarkImage && (
        <div style={{ position: 'absolute', bottom: '10px', left: '10px', borderRadius: '50%', overflow: 'hidden' }}>
          <img src={watermarkImage} alt="Watermark" style={{ maxWidth: '100px', borderRadius: '50%' }} />
        </div>
      )}
      <input type="file" accept="image/*" onChange={handleImageChange} />
      {/* <input type="text" placeholder="Enter text" value={userText} onChange={handleTextChange} style={{ margin: '10px' }} /> */}
      <button onClick={addWatermark}>Add Watermark</button>
      <button onClick={downloadWithWatermark}>Download with Watermark</button>
    </div>
  );
};

export default VideoWatermark;





